{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d20c17-11fe-4afd-a559-9f8bd156f42d",
   "metadata": {},
   "source": [
    "# Training our model\n",
    "In this notebook, we will be using 'Segmentation_models.pytorch' to setup the different neural network architectures and experiment with different parameters. We will be using 'Albumentations' for data augmentation, given we have a pretty small dataset to work with. The whole implementation is based on pytorch, so that will be the 'glue' in our project, to put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6bea2-a886-4c40-92fa-540fc9971b65",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb1160-a3cb-4818-a9e7-29d8a03a38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Data visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Data loading and manipulation\n",
    "from torch.utils.data import DataLoader\n",
    "from packages.dataset import Dataset\n",
    "import albumentations as albu\n",
    "from packages.helpers import *\n",
    "\n",
    "# Machine Learning model and training\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "def run():\n",
    "    torch.multiprocessing.freeze_support()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33177c5c-d859-4c11-8dcc-7d294ebcaa25",
   "metadata": {},
   "source": [
    "# 2. Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5f41b-3a86-4417-a9db-cf02b7650989",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'data/images'\n",
    "MASKS_DIR = 'data/masks'\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "\n",
    "PANELS, BACKGROUND = 0, 1\n",
    "\n",
    "\n",
    "MASK_VALUE = PANELS     # SPECIFY WHICH CLASS THE MODEL SHOULD TRAIN ON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66b1f3-3c57-44e2-a8cd-1c8ff921e54a",
   "metadata": {},
   "source": [
    "# 3. Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60740af-0c05-4c1b-be8b-f9664d8ae0d8",
   "metadata": {},
   "source": [
    "### 3.1. Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb9c8b-2133-43f3-aefe-e25a1473260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'valannot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67c41a-e12e-42d4-8685-f05f810de7cb",
   "metadata": {},
   "source": [
    "### 3.2. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff7580-2bf8-4ef8-bd0a-4aa771219c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at data we have\n",
    "dataset = Dataset(x_train_dir, y_train_dir, classes=['solar panel'], mask_value=MASK_VALUE)\n",
    "\n",
    "image, mask = dataset[5] # get some sample\n",
    "visualize(\n",
    "    image=image, \n",
    "    mask=mask.squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfbc237-2fa5-4690-a58e-0cc49aabad96",
   "metadata": {},
   "source": [
    "# 4. Augmentations\n",
    "As we have a small dataset, we want to increase the amount of data and prevent model overfitting. \n",
    "For this task, we will apply a large number of different augmentations :\n",
    "* horizontal flip\n",
    "* affine transforms\n",
    "* perspective transforms\n",
    "* brightness/contrast/colors manipulations\n",
    "* image bluring and sharpening\n",
    "* gaussian noise\n",
    "* random crops\n",
    "\n",
    "To do so, we will use the library called 'Albumentations'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860e599-7f3b-4649-a4b9-fef3d9cddce3",
   "metadata": {},
   "source": [
    "### 4.1. Visualization of augmented results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b075e2a-e5ee-4cb7-9662-ac2c5eaeb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmented_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    classes=['solar panel'],\n",
    "    mask_value=MASK_VALUE\n",
    ")\n",
    "\n",
    "# same image with different random transforms\n",
    "for i in range(3):\n",
    "    image, mask = augmented_dataset[5]\n",
    "    visualize(image=image, mask=mask.squeeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feebef9-3208-4f46-8231-e9eafa8eb78c",
   "metadata": {},
   "source": [
    "# 5. Setting up training environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330e306-1cf5-41bb-8a82-4a8befd84af1",
   "metadata": {},
   "source": [
    "### 5.1. Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8d86c-6f4f-40b7-9d2f-a41be3bc4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet101'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['solar panel']\n",
    "#ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496f865-e811-4a9d-86d7-0decc4a180fa",
   "metadata": {},
   "source": [
    "### 5.2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372faed-969a-4ef3-9c76-c44e4bd1775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(mask_value=MASK_VALUE), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    mask_value=MASK_VALUE\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(mask_value=MASK_VALUE), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    mask_value=MASK_VALUE\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a86567-6739-4f79-a395-c25f65057eb7",
   "metadata": {},
   "source": [
    "### 5.3. Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2671dc1-cd7e-4432-a4c8-9a27eb05fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "loss.__name__ = \"SoftBCEWithLogitsLoss\"\n",
    "\n",
    "# Metrics\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    smp.utils.metrics.Fscore(),\n",
    "    smp.utils.metrics.Accuracy(),\n",
    "    smp.utils.metrics.Recall(),\n",
    "    smp.utils.metrics.Precision(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28fc3ce-2519-4c31-973c-34ebd4fca924",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aec0cf-0504-4459-b66e-9281562b6116",
   "metadata": {},
   "source": [
    "### 6.1. Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464affc4-d0ea-404d-a49f-dc22ce7a3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    # activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "# Optimization\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb24894-be96-4ba6-908e-4661677766f3",
   "metadata": {},
   "source": [
    "### 6.2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1cedd-ac9e-4778-9c1e-8316475a7451",
   "metadata": {},
   "source": [
    "#### 6.4.1. Creating epoch runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767ab2-4bfb-4417-be54-bf7fd35defe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e493ee0-ecab-4dce-a726-ab9195f3b893",
   "metadata": {},
   "source": [
    "##### 6.4.2. Training the model for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e424a-51de-4208-9da5-3892709905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for 100 epochs\n",
    "\n",
    "max_score = 0\n",
    "train_logs = []\n",
    "valid_logs = []\n",
    "\n",
    "max_epochs = 200\n",
    "epochs = 100\n",
    "\n",
    "for i in range(0, max_epochs):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "   \n",
    "\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, f'./models/best_model_unet_{MASK_VALUE}_{epochs}.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(\"100 epochs trained, dumping logs...\")\n",
    "        with open(f'./logs/train_logs_unet_{MASK_VALUE}_{epochs}.json', \"w\") as write_file:\n",
    "            json.dump(train_logs, write_file)\n",
    "\n",
    "        with open(f'./logs/valid_logs_unet_{MASK_VALUE}_{epochs}.json', \"w\") as write_file:\n",
    "            json.dump(valid_logs, write_file)\n",
    "      \n",
    "        epochs += 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1ded7-08bd-4554-809a-1455bba3383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./logs/train/train_logs_unet_{MASK_VALUE}.json\", \"w\") as write_file:\n",
    "    json.dump(train_logs, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ac02b-a819-4913-b26d-792c6633bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./logs/valid/valid_logs_unet_{MASK_VALUE}.json\", \"w\") as write_file:\n",
    "    json.dump(valid_logs, write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
