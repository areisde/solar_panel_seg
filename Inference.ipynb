{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9f88ee-ce3b-4031-9d74-63207e33e42c",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Once we have a trained a model, we want to see how well it performs in the test set.\n",
    "We would also like to compare performance between the models, so this is what we are going to do in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e43f6-726e-46c1-8113-884f682b5a83",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73710355-a14b-45a4-b561-8c3bf589c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "import gc\n",
    "\n",
    "# Data visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Data loading and manipulation\n",
    "from torch.utils.data import DataLoader\n",
    "from packages.dataset import Dataset\n",
    "import albumentations as albu\n",
    "from packages.helpers import *\n",
    "\n",
    "# Machine Learning model and training\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Clean cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1bcdbe-544d-4abc-8f5d-f3db9a321116",
   "metadata": {},
   "source": [
    "# 2. Model and data\n",
    "We are going to fetch a previsouly trained model in the \"models\" folder and use to infer predictions on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07ace1-62bd-490b-b51a-aca5e4be58c8",
   "metadata": {},
   "source": [
    "### 2.1. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625f693-8628-4dce-a1a2-dac88c10dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "CLASSES = ['solar panel']\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "PANELS, BACKGROUND = 0, 1\n",
    "MASK_VALUE = PANELS     # Choose on which class the model was trained on\n",
    "EPOCHS = 200                # Indicate for how many epochs the model was run\n",
    "\n",
    "MODEL = 'unet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f098849-4fd2-4eb7-b5aa-dccec16230e5",
   "metadata": {},
   "source": [
    "### 2.1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22d663-a2dc-478c-8fa4-c6e103a07c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(f'./models/best_model_{MODEL}_{MASK_VALUE}_{EPOCHS}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3d68e-eb2b-4caa-8268-76a1991c0b70",
   "metadata": {},
   "source": [
    "### 2.2. Setup test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b52186-97d1-4433-b131-29895e19292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for testing data\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'testannot')\n",
    "\n",
    "# Parameters\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# Build dataset\n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    "    mask_value=MASK_VALUE\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293543d-dcd3-436c-8c3c-080fba991151",
   "metadata": {},
   "source": [
    "# 3. Evaluate model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17951cf0-c173-49ba-bbae-41ba8803bfbc",
   "metadata": {},
   "source": [
    "### 3.1. Loss and optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd3988-5f04-4e5f-a239-68abe37c7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smp.utils.losses.DiceLoss()\n",
    "loss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "loss.__name__ = \"SoftBCEWithLogitsLoss\"\n",
    "\n",
    "# loss_weights = [1, 100] # 1 for background and 10 for solar panel\n",
    "# loss = smp.losses.CategoricalCELoss(class_weights=loss_weights)\n",
    "# loss.__name__ = \"CategoricalCELoss\"\n",
    "\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    smp.utils.metrics.Fscore(),\n",
    "    smp.utils.metrics.Accuracy(),\n",
    "    smp.utils.metrics.Recall(),\n",
    "    smp.utils.metrics.Precision(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5616519-e64d-4a8d-bf1d-c438d50966bc",
   "metadata": {},
   "source": [
    "### 3.2. Run testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83bda1-94b2-451a-8fb3-4ddcf0cee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392283ec-ace0-4696-b16c-d23fa5688fa0",
   "metadata": {},
   "source": [
    "# 4. Extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a78fbd-f3e0-4105-ac5e-3e490f54cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(test_dataset, threshold):\n",
    "\n",
    "    image, gt_mask = test_dataset\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy())\n",
    "    pr_mask[pr_mask <= threshold] = 0\n",
    "    pr_mask[pr_mask > threshold] = 1\n",
    "\n",
    "    return gt_mask, pr_mask\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736a951-b240-49b8-bc8d-cedc6769171b",
   "metadata": {},
   "source": [
    "# 5. Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb29be-82d5-4358-af58-eeb558972135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    x_test_dir, y_test_dir, \n",
    "    classes=CLASSES,\n",
    "    mask_value=MASK_VALUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metrics(truth, pre):\n",
    "\n",
    "    gt = torch.from_numpy(truth)\n",
    "    pred = torch.from_numpy(pre)\n",
    "\n",
    "\n",
    "    tp = torch.sum((pred == (not MASK_VALUE)) * (gt == (not MASK_VALUE)))          # true positives: all pixels where both prediction and ground truth is one (solar panel)\n",
    "    fp = torch.sum((pred == (not MASK_VALUE)) * (gt == (MASK_VALUE)))          # false positives: prediction = one, ground truth = 0 (background)\n",
    "    fn = torch.sum((pred == (MASK_VALUE)) * (gt == (not MASK_VALUE)))          # false negatives: inverse\n",
    "\n",
    "\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn) \n",
    "    \n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2aa78d-df8f-4381-9065-0ef209346ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is a solar panel prediction and 1 is background prediction\n",
    "\n",
    "if MASK_VALUE == BACKGROUND:\n",
    "    threshold = 0.8\n",
    "else:\n",
    "    threshold = 0.1\n",
    "\n",
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "\n",
    "    \n",
    "    gt_mask, pr_mask = get_masks(test_dataset[n],threshold=threshold)\n",
    "    precision, recall = custom_metrics(gt_mask, pr_mask)\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )\n",
    "    print(f'precision: {precision}, recall: {recall}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e96ed8",
   "metadata": {},
   "source": [
    "## 6. Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_array = []\n",
    "recall_array = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "\n",
    "    gt_mask, pr_mask = get_masks(test_dataset[i],threshold=threshold)\n",
    "\n",
    "    precision, recall = custom_metrics(gt_mask, pr_mask)\n",
    "\n",
    "    if not precision.isnan():\n",
    "        precision_array.append(float(precision))\n",
    "\n",
    "    if not recall.isnan():\n",
    "        recall_array.append(float(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to json\n",
    "with open(f'./metrics/test_metrics_{MODEL}_{MASK_VALUE}_{EPOCHS}.json', 'w') as f:\n",
    "    json.dump({'precision': precision_array, 'recall': recall_array}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'precision: {np.array(precision_array).mean()}')\n",
    "print(f'recall: {np.array(recall_array).mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e89fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
