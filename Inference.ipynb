{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9f88ee-ce3b-4031-9d74-63207e33e42c",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Once we have a trained a model, we want to see how well it performs in the test set.\n",
    "We would also like to compare performance between the models, so this is what we are going to do in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e43f6-726e-46c1-8113-884f682b5a83",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73710355-a14b-45a4-b561-8c3bf589c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "\n",
    "# Data visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Data loading and manipulation\n",
    "from torch.utils.data import DataLoader\n",
    "from aux.dataset import Dataset\n",
    "import albumentations as albu\n",
    "from aux.helpers import *\n",
    "\n",
    "# Machine Learning model and training\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1bcdbe-544d-4abc-8f5d-f3db9a321116",
   "metadata": {},
   "source": [
    "# 2. Model and data\n",
    "We are going to fetch a previsouly trained model in the \"models\" folder and use to infer predictions on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db07ace1-62bd-490b-b51a-aca5e4be58c8",
   "metadata": {},
   "source": [
    "### 2.1. Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3625f693-8628-4dce-a1a2-dac88c10dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "CLASSES = ['solar panel']\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f098849-4fd2-4eb7-b5aa-dccec16230e5",
   "metadata": {},
   "source": [
    "### 2.1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f22d663-a2dc-478c-8fa4-c6e103a07c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = torch.load('./best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3d68e-eb2b-4caa-8268-76a1991c0b70",
   "metadata": {},
   "source": [
    "### 2.2. Setup test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34b52186-97d1-4433-b131-29895e19292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for testing data\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'testannot')\n",
    "\n",
    "# Parameters\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# Build dataset\n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293543d-dcd3-436c-8c3c-080fba991151",
   "metadata": {},
   "source": [
    "# 3. Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83bda1-94b2-451a-8fb3-4ddcf0cee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736a951-b240-49b8-bc8d-cedc6769171b",
   "metadata": {},
   "source": [
    "# 4. Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb29be-82d5-4358-af58-eeb558972135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    x_test_dir, y_test_dir, \n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2aa78d-df8f-4381-9065-0ef209346ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
